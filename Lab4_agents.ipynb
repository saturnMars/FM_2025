{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saturnMars/FM_2025/blob/main/Lab4_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed9965fa",
      "metadata": {
        "id": "ed9965fa"
      },
      "source": [
        "# Agent playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2f0e92",
      "metadata": {
        "id": "fc2f0e92"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain_openai langchain_huggingface langchain_community langchain_tavily"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a40ef73",
      "metadata": {
        "id": "5a40ef73"
      },
      "source": [
        "# Initialize the base language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dda4be8",
      "metadata": {
        "id": "1dda4be8"
      },
      "outputs": [],
      "source": [
        "local_inference = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "055bb9cb",
      "metadata": {
        "id": "055bb9cb"
      },
      "source": [
        "### A) Cloud inference\n",
        "1. via [*Hugging Face’s Inference Providers*](https://huggingface.co/docs/inference-providers/en/index)\n",
        "    - Create an account for the Hugging Face platform: [huggingface.co/join](https://huggingface.co/join)\n",
        "    - Get the API key from dashboard: [huggingface.co/docs/hub/en/security-tokens](https://huggingface.co/docs/hub/en/security-tokens)\n",
        "2. via [*OpenAI API*](https://auth.openai.com)\n",
        "    - Create a new OpenAI account (free credits for new accounts): [auth.openai.com/create-account](https://auth.openai.com/create-account)\n",
        "    - Generate the API key from the dashboard: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)\n",
        "3. via the [OpenRouter platform](https://openrouter.ai/)\n",
        "    - Create an account: [openrouter.ai](https://openrouter.ai/)\n",
        "    - Create a new API key: [openrouter.ai/settings/keys](https://openrouter.ai/settings/keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96e2cee",
      "metadata": {
        "id": "f96e2cee"
      },
      "outputs": [],
      "source": [
        "from os import environ\n",
        "environ[\"HF_TOKEN\"] = \"\"\n",
        "environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c13a9de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c13a9de",
        "outputId": "7a4db4ba-1c81-4503-d07e-924db655ec8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloud inference: model: \"gpt-5-nano\"\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Cloud inference via OpenAI\n",
        "if not local_inference and environ.get('OPENAI_API_KEY'):\n",
        "    llm_model = ChatOpenAI(model=\"gpt-5-nano\", api_key=environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "    print(f\"Cloud inference: model: \\\"{llm_model.model_name}\\\"\")\n",
        "\n",
        "# Cloud inference via HuggingFace\n",
        "elif not local_inference and environ.get('HF_TOKEN'):\n",
        "    llm_model = ChatOpenAI(\n",
        "        base_url=\"https://router.huggingface.co/v1\",\n",
        "        model=\"Qwen/Qwen3-Next-80B-A3B-Instruct\", # (1) Qwen/Qwen3-Next-80B-A3B-Instruct || (2) openai/gpt-oss-120b (3) CohereLabs/c4ai-command-r7b-12-2024\n",
        "        api_key=environ[\"HF_TOKEN\"])\n",
        "    print(f\"Cloud inference ({llm_model.openai_api_base}): model: \\\"{llm_model.model_name}\\\"\")\n",
        "else:\n",
        "    llm_model = ChatOpenAI(\n",
        "        base_url=\"https://openrouter.ai/api/v1\",\n",
        "        model=\"nvidia/nemotron-nano-9b-v2:free\", # (1) mistralai/mistral-small-3.2-24b-instruct:free (1) nvidia/nemotron-nano-9b-v2:free\n",
        "        api_key=\"\")\n",
        "\n",
        "    print(f\"Cloud inference ({llm_model.openai_api_base}): model: \\\"{llm_model.model_name}\\\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1e9733c",
      "metadata": {
        "id": "e1e9733c"
      },
      "source": [
        "### B) Local inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fc4d344",
      "metadata": {
        "id": "1fc4d344"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
        "\n",
        "if local_inference:\n",
        "    llm_model = ChatHuggingFace(\n",
        "        llm = HuggingFacePipeline.from_model_id(\n",
        "            model_id=\"allenai/OLMo-2-0425-1B-Instruct\", #  allenai/OLMo-2-0425-1B-Instruct | Qwen/Qwen3-4B-Instruct-2507\n",
        "            task =\"text-generation\",\n",
        "            pipeline_kwargs={'dtype':\"bfloat16\"}\n",
        "        ))\n",
        "    print(f\"Local Inference: \\\"{llm_model.llm.model_id}\\\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7d0becb",
      "metadata": {
        "id": "f7d0becb"
      },
      "source": [
        "# Get the API token\n",
        "1. Create an account on [Tavily platform](https://app.tavily.com/home)\n",
        "2. Create a new API key: [https://app.tavily.com/home](https://app.tavily.com/home)\n",
        "\n",
        "\n",
        "# Initialize the tool\n",
        "This code demonstrates how to use the `TavilySearch` tool from the `langchain_tavily` package to perform a web search within a LangChain workflow.\n",
        "2. It imports the TavilySearch class, which is a tool designed to query the Tavily Search API and return structured search results, such as URLs, snippets, and optionally images or answers.\n",
        "3. The invoke method is then called with the query `\"What is Italy’s current public debt?\"`.\n",
        "    - This method sends the query to the Tavily API and returns the search results as a dictionary containing information such as the original query, a list of result items (with titles, URLs, and content snippets), and possibly other metadata.\n",
        "4. The results are printed to the output pane, allowing you to inspect the returned data.\n",
        "\n",
        "The code also shows how to organize tools for later use by placing the search tool into a list called tools. This is useful when building more complex agent workflows that may use multiple tools for different tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d76fe7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28d76fe7",
        "outputId": "d1a9b3ba-d523-4120-bfcd-f59463c500c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"query\": \"What is Italy’s current public debt?\",\n",
            "    \"follow_up_questions\": null,\n",
            "    \"answer\": null,\n",
            "    \"images\": [],\n",
            "    \"results\": [\n",
            "        {\n",
            "            \"url\": \"https://en.wikipedia.org/wiki/Italian_government_debt\",\n",
            "            \"title\": \"Italian government debt - Wikipedia\",\n",
            "            \"content\": \"As of January 2014, the Italian government debt stands at €2.1 trillion (131.1% of GDP). Italy has the lowest share of public debt held by non-residents of all\",\n",
            "            \"score\": 0.91156644,\n",
            "            \"raw_content\": null\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://www.reuters.com/markets/europe/italys-public-debt-tops-3-trillion-euros-highest-record-2025-01-15/\",\n",
            "            \"title\": \"Italy's public debt tops 3 trillion euros, highest on record | Reuters\",\n",
            "            \"content\": \"Italy's debt climbed to 3,005.2 billion euros in November, compared with 2,981.3 billion euros in the previous month, Bank of Italy data showed.\",\n",
            "            \"score\": 0.890761,\n",
            "            \"raw_content\": null\n",
            "        }\n",
            "    ],\n",
            "    \"response_time\": 0.74,\n",
            "    \"request_id\": \"3f15ddd7-fdd8-4718-87d3-a82200db02f2\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "from json import dumps\n",
        "\n",
        "# Initialize the Tavily Search tool\n",
        "search_tool = TavilySearch(max_results=2, tavily_api_key = \"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\")\n",
        "\n",
        "# Try out the search tool\n",
        "search_results = search_tool.invoke(input = \"What is Italy’s current public debt?\")\n",
        "print(dumps(search_results, indent=4, ensure_ascii = False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c049fa0a",
      "metadata": {
        "id": "c049fa0a"
      },
      "source": [
        "# Invoke the agent with a user query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd983b4c",
      "metadata": {
        "id": "cd983b4c"
      },
      "outputs": [],
      "source": [
        "query = \"What's the weather like today in Trento, Italy?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13385960",
      "metadata": {
        "id": "13385960"
      },
      "source": [
        "### A) without the search tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06d66f60",
      "metadata": {
        "id": "06d66f60"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_agent\n",
        "agent_executor = create_agent(\n",
        "    model = llm_model,\n",
        "    system_prompt = \"You are a helpful assistant that exploits all available tools to find up-to-date information.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29560cf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29560cf9",
        "outputId": "88780152-7d23-4243-ed93-5cbebd35ee6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What's the weather like today in Trento, Italy?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I can look that up for you. Do you want me to fetch the latest current conditions for Trento, Italy now? If yes, I’ll include:\n",
            "- current temperature and weather (e.g., sunny, cloudy, rain)\n",
            "- precipitation chances\n",
            "- wind\n",
            "- today’s high/low\n",
            "- a brief forecast for the rest of the day (in °C)\n",
            "\n",
            "If you have a preferred weather source (e.g., Meteo.it, The Weather Channel, AccuWeather), tell me and I’ll use that.\n"
          ]
        }
      ],
      "source": [
        "# Define the input message\n",
        "input_message = {\"messages\": {\"role\": \"user\", \"content\": query}}\n",
        "\n",
        "# Invoke the agent\n",
        "response = agent_executor.invoke(input_message)\n",
        "\n",
        "# Print the response\n",
        "for message in response[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9adb36",
      "metadata": {
        "id": "2a9adb36"
      },
      "source": [
        "### B) with the search tool\n",
        "![image.png](https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?w=840&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=bd932835b919f5e58be77221b6d0f194)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b98c8b",
      "metadata": {
        "id": "84b98c8b"
      },
      "outputs": [],
      "source": [
        "agent_executor = create_agent(\n",
        "    model = llm_model,\n",
        "    tools = [search_tool],\n",
        "    system_prompt = \"You are a helpful assistant that exploits all available tools to find up-to-date information.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82852a2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82852a2b",
        "outputId": "07944953-4a5f-4de3-fb41-d6400ce784f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What's the weather like today in Trento, Italy?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  tavily_search (call_EUPkc6gceLqkT7LGvpqp8jfV)\n",
            " Call ID: call_EUPkc6gceLqkT7LGvpqp8jfV\n",
            "  Args:\n",
            "    query: Trento weather today\n",
            "    time_range: None\n",
            "    start_date: None\n",
            "    end_date: None\n",
            "    include_domains: None\n",
            "    exclude_domains: None\n",
            "    search_depth: advanced\n",
            "    include_images: False\n",
            "    include_favicon: False\n",
            "    topic: general\n",
            "  tavily_search (call_iUMizfHhJupcFm5VCi8AwQp2)\n",
            " Call ID: call_iUMizfHhJupcFm5VCi8AwQp2\n",
            "  Args:\n",
            "    query: Trento meteo oggi\n",
            "    time_range: None\n",
            "    start_date: None\n",
            "    end_date: None\n",
            "    include_domains: ['meteo.it', 'ilmeteo.it', 'weather.com', 'yr.no', 'accuweather.com']\n",
            "    exclude_domains: None\n",
            "    search_depth: advanced\n",
            "    include_images: False\n",
            "    include_favicon: False\n",
            "    topic: general\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"Trento weather today\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.weather25.com/europe/italy/trentino-alto-adige/trento?page=month&month=November\", \"title\": \"Trento weather in November 2025 - Weather25.com\", \"content\": \"weather25.com\\nSearch\\nweather in Italy\\nRemove from your favorite locations\\nAdd to my locations\\nShare\\nweather in Italy\\n\\n# Trento weather in November 2025\\n\\nClear\\nSunny\\nClear\\nSunny\\nOvercast\\nLight drizzle\\nLight rain\\nLight rain\\nPartly cloudy\\nClear\\nLight drizzle\\nFog\\nMist\\nClear\\n\\n## The average weather in Trento in November\\n\\nThe weather in Trento in November is very cold with temperatures between 1°C and 8°C, warm clothes are a must. [...] | Sun | Mon | Tue | Wed | Thu | Fri | Sat |\\n ---  ---  --- \\n|  |  |  |  |  |  | 1 Light rain 12° /5° |\\n| 2 Partly cloudy 11° /4° | 3 Light rain shower 12° /4° | 4 Patchy rain possible 9° /1° | 5 Overcast 9° /1° | 6 Light rain shower 8° /0° | 7 Light rain shower 11° /1° | 8 Heavy rain 8° /1° |\\n| 9 Sunny 8° /1° | 10 Partly cloudy 9° /1° | 11 Sunny 7° /-1° | 12 Sunny 11° /-2° | 13 Sunny 13° /-1° | 14 Sunny 7° /-1° | 15 Overcast 9° /1° | [...] | 16 Light drizzle 10° /10° | 17 Light rain 10° /8° | 18 Light rain 8° /-2° | 19 Partly cloudy 2° /-1° | 20 Sunny 3° /-2° | 21 Light drizzle 7° /3° | 22 Fog 6° /1° |\\n| 23 Mist 6° /0° | 24 Sunny 11° /4° | 25 Mist 7° /-2° | 26 Partly cloudy 7° /0° | 27 Heavy rain 6° /1° | 28 Partly cloudy 7° /0° | 29 Partly cloudy 6° /-2° |\\n| 30 Sunny 5° /-2° |  |  |  |  |  |  |\", \"score\": 0.9392538, \"raw_content\": null}, {\"url\": \"https://www.accuweather.com/en/it/trento/216357/november-weather/216357\", \"title\": \"Trento, Trentino-Alto Adige, Italy Monthly Weather | AccuWeather\", \"content\": \"# Trento, Trentino-Alto Adige\\n\\nTrento\\n\\nTrentino-Alto Adige\\n\\n## Around the Globe\\n\\nAround the Globe\\n\\n### Hurricane Tracker\\n\\n### Severe Weather\\n\\n### Radar & Maps\\n\\n### News & Features\\n\\n### Astronomy\\n\\n### Business\\n\\n### Climate\\n\\n### Health\\n\\n### Recreation\\n\\n### Sports\\n\\n### Travel\\n\\n### Warnings\\n\\n### Data Suite\\n\\n### Forensics\\n\\n### Advertising\\n\\n### Superior Accuracy™\\n\\n### Video\\n\\n## Monthly\\n\\n## November\\n\\n## 2025\\n\\n## Daily\\n\\n## Temperature Graph\\n\\n## Further Ahead\\n\\nFurther Ahead\\n\\n### December 2025 [...] ### January 2026\\n\\n### February 2026\\n\\n## Around the Globe\\n\\nAround the Globe\\n\\n### Hurricane Tracker\\n\\n### Severe Weather\\n\\n### Radar & Maps\\n\\n### News\\n\\n### Video\\n\\nTop Stories\\n\\nWinter Weather\\n\\nEarly snow expands from Great Lakes to Northeast, interior Southeast\\n\\n1 hour ago\\n\\nWeather News\\n\\nTornado tears through southern Brazil, killing at least six\\n\\n1 day ago\\n\\nWinter Weather\\n\\nArctic air advances, ushering in coldest air of the season for some\\n\\n1 hour ago\\n\\nAstronomy\", \"score\": 0.6739866, \"raw_content\": null}], \"response_time\": 4.24, \"request_id\": \"ec4f6a17-0ca9-454d-9878-05153b458311\"}\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search\n",
            "\n",
            "{\"query\": \"Trento meteo oggi\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://weather.com/weather/tenday/l/Trento+Trentino+38121+Italy?canonicalCityId=e67b3af9f8a2a341161c129f8f724eb1\", \"title\": \"10-Day Weather Forecast for Trento, Trentino 38121, Italy\", \"content\": \"Skip to Main ContentAccessibility Help\\n\\nAdvertisement\\n\\nAdvertisement\\n\\nAdvertisement\\n\\n# 10 Day Weather- Trento, Trentino, Italy\\n\\nAs of 10:42 am CET\\n\\n## Today\\n\\nSunny\\n\\n65°/43°\\n\\n3%\\n\\n## Day\\n\\n65°\\n\\n3%\\n\\nSSW 4 mph\\n\\nPlentiful sunshine. High near 65F. Winds light and variable.\\n\\nHeads-up\\n\\nFlorida’s Iguanas Will Be ‘Fainting’ Again\\n\\n Humidity57%\\n UV Index2 of 11\\n Sunrise7:10 am\\n Sunset4:48 pm\\n\\n## Night\\n\\n43°\\n\\n5%\\n\\nNNW 3 mph\\n\\nPartly cloudy skies. Low 43F. Winds light and variable. [...] 66°\\n\\n6%\\n\\nSW 4 mph\\n\\nExcept for a few afternoon clouds, mainly sunny. High 66F. Winds light and variable.\\n\\n Humidity61%\\n UV Index2 of 11\\n Sunrise7:13 am\\n Sunset4:45 pm\\n\\n## Night\\n\\n46°\\n\\n6%\\n\\nNW 3 mph\\n\\nPartly cloudy skies. Low 46F. Winds light and variable.\\n\\n Humidity75%\\n UV Index0 of 11\\n Moonrise12:00 am\\n Moonset2:00 pm\\n Waning Crescent\\n\\n## Fri 14\\n\\nMostly Sunny\\n\\n66°/49°\\n\\n6%\\n\\n## Day\\n\\n66°\\n\\n6%\\n\\nSW 5 mph\\n\\nA few passing clouds, otherwise generally sunny. High 66F. Winds light and variable.\", \"score\": 0.79675186, \"raw_content\": null}, {\"url\": \"https://www.accuweather.com/en/it/trento/216357/weather-forecast/216357\", \"title\": \"Trento, Trentino-Alto Adige, Italy Weather Forecast\", \"content\": \"0%  8 PM  45°\\n\\n0%  9 PM  44°\\n\\n0%  10 PM  43°\\n\\n0%\\n\\n## 10-Day Weather Forecast\\n\\nToday\\n\\n11/11\\n\\n59° 39°\\n\\nMostly sunny\\n\\nNight: Partly cloudy\\n\\n1% Wed\\n\\n11/12\\n\\n58° 40°\\n\\nSome clouds, then sunny\\n\\nClear\\n\\n1% Thu\\n\\n11/13\\n\\n58° 41°\\n\\nMostly sunny\\n\\nClear to partly cloudy\\n\\n0% Fri\\n\\n11/14\\n\\n57° 44°\\n\\nSunny\\n\\nBecoming cloudy\\n\\n1% Sat\\n\\n11/15\\n\\n54° 47°\\n\\nCloudy\\n\\nA couple of evening showers\\n\\n25% Sun\\n\\n11/16\\n\\n53° 45°\\n\\nLow clouds\\n\\nRain and drizzle late\\n\\n25% Mon\\n\\n11/17\\n\\n52° 43°\\n\\nRain and drizzle in the a.m. [...] ### Hurricane Tracker ### Severe Weather ### Radar & Maps\\n\\n### News & Features ### Astronomy ### Business ### Climate ### Health ### Recreation ### Sports ### Travel\\n\\nFor Business\\n\\n### Warnings ### Data Suite ### Forensics ### Advertising ### Superior Accuracy™\\n\\n### Video\\n\\n## Today  Hourly   Daily   Radar   MinuteCast®   Monthly   Air Quality   Health & Activities\\n\\n## Today's Weather\\n\\nTue, Nov 11\\n\\nMostly sunny Hi: 59°\\n\\nTonight: Partly cloudy Lo: 39°\\n\\n## Current Weather\\n\\n10:43 AM\\n\\n49°F [...] RealFeel® 55°\\n\\nSunny  More Details\\n\\nRealFeel Shade™ 51°\\n\\nWind N 2 mph\\n\\nWind Gusts 5 mph\\n\\nAir Quality Fair ## Looking Ahead\\n\\nExpect showers Saturday evening\\n\\n## Trento Weather Radar\\n\\nStatic Radar Temporarily Unavailable\\n\\nThank you for your patience as we work to get everything up and running again.\\n\\nRefresh Page\\n\\nClouds Temperature\\n\\n## Hourly Weather\\n\\n11 AM  53°\\n\\n0%  12 PM  57°\\n\\n0%  1 PM  58°\\n\\n0%  2 PM  59°\\n\\n0%  3 PM  57°\\n\\n0%  4 PM  54°\\n\\n0%  5 PM  52°\\n\\n0%  6 PM  49°\\n\\n0%  7 PM  46°\", \"score\": 0.7413937, \"raw_content\": null}], \"response_time\": 2.2, \"request_id\": \"88f18045-c8fd-419f-aabb-cead090c8a3b\"}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here's the current weather outlook for Trento, Italy today:\n",
            "\n",
            "- Sky: Mostly sunny to sunny\n",
            "- High / Low: about 18–19°C (65°F) today; about 6–7°C (43–45°F) overnight\n",
            "- Winds: light, from the southwest to NW depending on the moment\n",
            "- Humidity: moderate (roughly mid-50s to 60%)\n",
            "- UV index: typically low to moderate today\n",
            "\n",
            "Live checks from sources right now:\n",
            "- Weather.com: Today is sunny with a high around 65°F (18°C) and a low around 43°F (6°C).\n",
            "  Source: https://weather.com/weather/tenday/l/Trento+Trentino+38121+Italy?canonicalCityId=e67b3af9f8a2a341161c129f8f724eb1\n",
            "- AccuWeather: Today is listed as mostly sunny with a high near 59°F (15°C); current reading around 49°F (9°C) at 10:43 AM local time.\n",
            "  Source: https://www.accuweather.com/en/it/trento/216357/weather-forecast/216357\n",
            "\n",
            "If you’d like, I can fetch an exact live temperature and conditions right now for your exact moment.\n"
          ]
        }
      ],
      "source": [
        "# Define the input message\n",
        "input_message = {\"messages\": {\"role\": \"user\", \"content\": query}}\n",
        "\n",
        "# Invoke the agent\n",
        "response = agent_executor.invoke(input_message)\n",
        "\n",
        "# Print the response\n",
        "for message in response[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "535fc51a",
      "metadata": {
        "id": "535fc51a"
      },
      "source": [
        "# Create our custom tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb5f20a",
      "metadata": {
        "id": "7bb5f20a"
      },
      "outputs": [],
      "source": [
        "def get_exam_score(exam_name: str) -> dict:\n",
        "    \"\"\"Get the expected score for a given exam.\"\"\"\n",
        "\n",
        "    # For demonstration purposes, we assume a perfect score (we have high expectations!)\n",
        "    student_score = 30\n",
        "\n",
        "    return {\n",
        "        'exam_name': exam_name,\n",
        "        'range': (0, 30),\n",
        "        'score': student_score}\n",
        "\n",
        "def parse_result(score: int) -> dict:\n",
        "    \"\"\"Get the expected result (pass or fail) for a given score.\"\"\"\n",
        "\n",
        "    # For demonstration purposes, we assume a traditional passing threshold\n",
        "    pass_threshold = 18\n",
        "\n",
        "    # Context: exam is graded out of 30, with 18 as the passing threshold\n",
        "    results = {\n",
        "        'score': score,\n",
        "        'pass_threshold': pass_threshold,\n",
        "        'passed': score >= pass_threshold,\n",
        "        'cum_laude': False # sorry :/\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b01cad",
      "metadata": {
        "id": "29b01cad"
      },
      "outputs": [],
      "source": [
        "agent_executor = create_agent(\n",
        "    model = llm_model,\n",
        "    tools = [get_exam_score, parse_result],\n",
        "    system_prompt = \"You are a helpful assistant that exploits all available tools to find up-to-date information.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d88a89a4",
      "metadata": {
        "id": "d88a89a4"
      },
      "outputs": [],
      "source": [
        "query = 'Will I ever pass the FM 2025 exam?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b030c85c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b030c85c",
        "outputId": "1961f3f8-167c-4e6a-8420-2ae5490a190c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Will I ever pass the FM 2025 exam?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  get_exam_score (call_OxhfVbUv0jUPAUQ9M7FI3vWv)\n",
            " Call ID: call_OxhfVbUv0jUPAUQ9M7FI3vWv\n",
            "  Args:\n",
            "    exam_name: FM 2025\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: get_exam_score\n",
            "\n",
            "{\"exam_name\": \"FM 2025\", \"range\": [0, 30], \"score\": 30}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  parse_result (call_VaeAUs8S851bC8G1rxm1ylMx)\n",
            " Call ID: call_VaeAUs8S851bC8G1rxm1ylMx\n",
            "  Args:\n",
            "    score: 30\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: parse_result\n",
            "\n",
            "{\"score\": 30, \"pass_threshold\": 18, \"passed\": true, \"cum_laude\": false}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes. Based on the data, you have passed the FM 2025 exam.\n",
            "\n",
            "- Score: 30 out of 30\n",
            "- Pass threshold: 18\n",
            "- Passed: True\n",
            "- Cum Laude: false (not at the top honors)\n",
            "\n",
            "If you’d like, I can help you plan next steps (certificate actions, study plans for future exams, or strategies to aim for cum laude if applicable).\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"messages\": {\"role\": \"user\", \"content\": query}})\n",
        "\n",
        "# Print the response\n",
        "for message in response[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turnaround to avoid API limitation (rate-limited upstream)\n",
        "from time import sleep\n",
        "sleep(5)"
      ],
      "metadata": {
        "id": "pCP6rvVXmqz5"
      },
      "id": "pCP6rvVXmqz5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2d92ddea",
      "metadata": {
        "id": "2d92ddea"
      },
      "source": [
        "# Human in the loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ce81553",
      "metadata": {
        "id": "9ce81553"
      },
      "outputs": [],
      "source": [
        "def parse_result(score: int) -> dict:\n",
        "    \"\"\"Get the expected result (pass or fail) for a given score.\"\"\"\n",
        "\n",
        "    # For demonstration purposes, we assume a traditional passing threshold\n",
        "    pass_threshold = 18\n",
        "\n",
        "    # Ask for human approval if the score is passing\n",
        "    accepted = None\n",
        "    if score >= pass_threshold:\n",
        "        user_input = input(f\"Do you accept a score equal to {score} (yes/no): \").strip().lower()\n",
        "        accepted = True if user_input == 'yes' else False\n",
        "\n",
        "    # Context: exam is graded out of 30, with 18 as the passing threshold\n",
        "    results = {\n",
        "        'score': score,\n",
        "        'pass_threshold': pass_threshold,\n",
        "        'passed': score >= pass_threshold,\n",
        "        'cum_laude': False, # sorry :/\n",
        "        'acceptedByStudent': accepted\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e662af4",
      "metadata": {
        "id": "8e662af4"
      },
      "outputs": [],
      "source": [
        "agent_executor = create_agent(\n",
        "    model = llm_model,\n",
        "    tools = [get_exam_score, parse_result],\n",
        "    system_prompt = \"You are a helpful assistant that exploits all available tools to find up-to-date information.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48fb5c67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48fb5c67",
        "outputId": "29100f9e-f978-4df2-a469-1a3c2bb698e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you accept a score equal to 30 (yes/no): no\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Will I ever pass the FM 2025 exam?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  get_exam_score (call_cUtFCfE2CeboDPqas6MvbLme)\n",
            " Call ID: call_cUtFCfE2CeboDPqas6MvbLme\n",
            "  Args:\n",
            "    exam_name: FM 2025\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: get_exam_score\n",
            "\n",
            "{\"exam_name\": \"FM 2025\", \"range\": [0, 30], \"score\": 30}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  parse_result (call_wv31camrzcVjG1RQaceFBWPJ)\n",
            " Call ID: call_wv31camrzcVjG1RQaceFBWPJ\n",
            "  Args:\n",
            "    score: 30\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: parse_result\n",
            "\n",
            "{\"score\": 30, \"pass_threshold\": 18, \"passed\": true, \"cum_laude\": false, \"acceptedByStudent\": false}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes. Based on the data, you have already achieved a score of 30/30 on the FM 2025 exam, which is above the pass threshold of 18. So you will pass (you’ve effectively passed this attempt). Cum laude was not reached in this result.\n",
            "\n",
            "If you’re aiming for cum laude or want to feel more confident for future attempts, I can help you create a targeted study plan. Options:\n",
            "- Identify common weak areas and focus revision on those topics.\n",
            "- Create a 4–6 week study schedule with daily practice, timed full-length mock exams, and review of every mistake.\n",
            "- Implement exam strategies (time management, process of elimination, prioritizing high-yield topics).\n",
            "\n",
            "Tell me your available study time and any topics you find challenging, and I’ll tailor a plan. I can also run additional mock exams or simulate different scoring scenarios if you’d like.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"messages\": {\"role\": \"user\", \"content\": query}}, config = {\"configurable\": {\"thread_id\": \"101\"}})\n",
        "\n",
        "# Print the response\n",
        "for message in response[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "677edcda",
      "metadata": {
        "id": "677edcda"
      },
      "source": [
        "# Conversational agents (i.e., ChatBots)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "947ec79e",
      "metadata": {
        "collapsed": true,
        "id": "947ec79e"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63ea2a84",
      "metadata": {
        "id": "63ea2a84"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories.in_memory import ChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.runnables import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
        "from langchain_core.runnables import RunnableMap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad4b11d8",
      "metadata": {
        "id": "ad4b11d8"
      },
      "outputs": [],
      "source": [
        "store = {}\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    \"\"\"Retrieve or create chat history for a session.\"\"\"\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "7v_nCtpAMOdy"
      },
      "id": "7v_nCtpAMOdy"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts.chat import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "QbTg_AKMiGro"
      },
      "id": "QbTg_AKMiGro",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
        "])\n",
        "\n",
        "# Chain the prompt with the LLM\n",
        "chain = prompt | llm_model\n",
        "\n",
        "# Create the chatbot with history support\n",
        "chatbot = RunnableWithMessageHistory(chain, get_session_history=get_session_history, input_messages_key=\"input\", history_messages_key=\"history\")"
      ],
      "metadata": {
        "id": "DPFkljz7M4EB"
      },
      "id": "DPFkljz7M4EB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "def get_response(user_message, history):\n",
        "\n",
        "    # Execute the model\n",
        "    response = chatbot.invoke(input = {\"input\": user_message}, config={\"configurable\": {\"session_id\": session_id}})\n",
        "\n",
        "    # Get the text\n",
        "    generated_text = response.content\n",
        "\n",
        "    # Clear text\n",
        "    matches = list(re.finditer(user_message, generated_text))\n",
        "    if matches:\n",
        "        last_match = matches[-1]\n",
        "        generated_text = generated_text[last_match.end() + 1 :]\n",
        "\n",
        "    return generated_text.strip()\n",
        "\n",
        "# Define the interface\n",
        "session_id = 'user1'\n",
        "interface = gr.ChatInterface(fn=get_response, type=\"messages\", title=f\"ChatBot\", examples=[\"Tell me a joke\", \"What's the capital of France?\", \"What is the population of Trento?\"])\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch(share = True, debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "WpDoJIU1Ko7Q",
        "outputId": "af91272a-6ee1-4f37-ff5a-6723a6a26a9f"
      },
      "id": "WpDoJIU1Ko7Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ba437e1ebe4108489c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ba437e1ebe4108489c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ba437e1ebe4108489c.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}