{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9965fa",
   "metadata": {},
   "source": [
    "# Agent playground\n",
    "![image.png](https://mintcdn.com/langchain-5e9cc07a/-_xGPoyjhyiDWTPJ/oss/images/agent.png?w=840&fit=max&auto=format&n=-_xGPoyjhyiDWTPJ&q=85&s=bd932835b919f5e58be77221b6d0f194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2f0e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.venv/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain_openai in ./.venv/lib/python3.10/site-packages (1.0.2)\n",
      "Requirement already satisfied: langchain_tavily in ./.venv/lib/python3.10/site-packages (0.2.13)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in ./.venv/lib/python3.10/site-packages (from langchain) (1.0.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.10/site-packages (from langchain) (2.12.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.41)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in ./.venv/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in ./.venv/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.venv/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./.venv/lib/python3.10/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./.venv/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in ./.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in ./.venv/lib/python3.10/site-packages (from langchain_openai) (2.7.1)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from langchain_openai) (0.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./.venv/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.10/site-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.9.18)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in ./.venv/lib/python3.10/site-packages (from langchain_tavily) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain_tavily) (1.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_openai langchain_tavily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40ef73",
   "metadata": {},
   "source": [
    "# Initialize the base language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dda4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_inference = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055bb9cb",
   "metadata": {},
   "source": [
    "### A) Cloud inference via [*Hugging Face’s Inference Providers*](https://huggingface.co/docs/inference-providers/en/index)\n",
    "- Get the API key from the Hugging Face platform: [huggingface.co/docs/hub/en/security-tokens](https://huggingface.co/docs/hub/en/security-tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"HF_TOKEN\"] = None \n",
    "environ[\"OPENAI_API_KEY\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c13a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Cloud inference via HuggingFace\n",
    "if not local_inference and environ.get('HF_TOKEN'):\n",
    "    llm_model = ChatOpenAI(\n",
    "        base_url=\"https://router.huggingface.co/v1\",\n",
    "        model=\"openai/gpt-oss-20b\", #\"Qwen/Qwen3-Next-80B-A3B-Instruct\", # openai/gpt-oss-20b\n",
    "        api_key=environ[\"HF_TOKEN\"])\n",
    "# Cloud inference via OpenAI\n",
    "elif not local_inference and environ.get('OPENAI_API_KEY'):\n",
    "    llm_model = ChatOpenAI(\n",
    "        model=\"gpt-5-nano\", # openai/gpt-oss-20b\n",
    "         api_key=environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e9733c",
   "metadata": {},
   "source": [
    "### B) Local inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fc4d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "\n",
    "if local_inference:\n",
    "    llm_model = ChatHuggingFace(\n",
    "        llm = HuggingFacePipeline.from_model_id(\n",
    "            model_id=\"microsoft/Phi-4-mini-instruct\", # google/gemma-3-4b-it | microsoft/Phi-4-mini-instruct | microsoft/Phi-4-mini-reasoning\n",
    "            task =\"text-generation\",\n",
    "            pipeline_kwargs={'dtype':\"bfloat16\"}\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3fa6101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: \"openai/gpt-oss-20b\" via \"https://router.huggingface.co/v1\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using model: \\\"{llm_model.model_name}\\\" via \\\"{llm_model.openai_api_base}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0becb",
   "metadata": {},
   "source": [
    "# Initialize the tool\n",
    "This code demonstrates how to use the `TavilySearch` tool from the `langchain_tavily` package to perform a web search within a LangChain workflow. \n",
    "1. It imports the TavilySearch class, which is a tool designed to query the Tavily Search API and return structured search results, such as URLs, snippets, and optionally images or answers.\n",
    "2. The invoke method is then called with the query `\"What is Italy’s current public debt?\"`. \n",
    "    - This method sends the query to the Tavily API and returns the search results as a dictionary containing information such as the original query, a list of result items (with titles, URLs, and content snippets), and possibly other metadata.\n",
    "3. The results are printed to the output pane, allowing you to inspect the returned data. \n",
    "\n",
    "The code also shows how to organize tools for later use by placing the search tool into a list called tools. This is useful when building more complex agent workflows that may use multiple tools for different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d76fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from json import dumps\n",
    "\n",
    "# Initialize the Tavily Search tool\n",
    "search_tool = TavilySearch(max_results=2, tavily_api_key = \"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\")\n",
    "\n",
    "# Try out the search tool\n",
    "#search_results = search_tool.invoke(input = \"What is Italy’s current public debt?\")\n",
    "#print(dumps(search_results, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049fa0a",
   "metadata": {},
   "source": [
    "# Invoke the agent with a user query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd983b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's the weather like today in Trento, Italy?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13385960",
   "metadata": {},
   "source": [
    "### A) without the search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06d66f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "agent_executor = create_agent(\n",
    "    model = llm_model,\n",
    "    system_prompt = \"You are a helpful assistant that exploits all available tools to find up-to-date information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29560cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the weather like today in Trento, Italy?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I can fetch live weather for Trento, Italy, but I don’t have real-time data loaded here. Want me to pull the latest conditions now? I’ll return current temperature, sky condition, any precipitation, wind, humidity, and a brief forecast for today, with the source. If you have a preferred weather site (e.g., Meteo.it, Weather.com, AccuWeather), tell me and I’ll use that.\n"
     ]
    }
   ],
   "source": [
    "# Define the input message\n",
    "input_message = {\"messages\": {\"role\": \"user\", \"content\": query}}\n",
    "\n",
    "# Invoke the agent\n",
    "response = agent_executor.invoke(input_message)\n",
    "\n",
    "# Print the response\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9adb36",
   "metadata": {},
   "source": [
    "### B) with the search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84b98c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_agent(\n",
    "    model = llm_model, \n",
    "    tools = [search_tool],\n",
    "    system_prompt = \"You are a helpful assistant that exploits all available tools to find up-to-date information.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82852a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the weather like today in Trento, Italy?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_920XSe28qeIs5OkIenMxAlHc)\n",
      " Call ID: call_920XSe28qeIs5OkIenMxAlHc\n",
      "  Args:\n",
      "    query: Trento weather today\n",
      "    search_depth: advanced\n",
      "    include_images: False\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Trento weather today\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.weather25.com/europe/italy/trentino-alto-adige/trento?page=month&month=November\", \"title\": \"Trento weather in November 2025 - Weather25.com\", \"content\": \"weather25.com\\nSearch\\nweather in Italy\\nRemove from your favorite locations\\nAdd to my locations\\nShare\\nweather in Italy\\n\\n# Trento weather in November 2025\\n\\nClear\\nClear\\nClear\\nPartly cloudy\\nClear\\nCloudy\\nOvercast\\nMist\\nModerate rain\\nPatchy rain possible\\nPartly cloudy\\nClear\\nLight rain\\nLight rain\\n\\n## The average weather in Trento in November\\n\\nThe weather in Trento in November is very cold with temperatures between 1°C and 8°C, warm clothes are a must. [...] | 16 Partly cloudy 12° /1° | 17 Sunny 10° /3° | 18 Light rain 7° /4° | 19 Light rain 7° /1° | 20 Light drizzle 6° /-1° | 21 Freezing fog 7° /0° | 22 Light rain shower 7° /-1° |\\n| 23 Partly cloudy 6° /-2° | 24 Partly cloudy 6° /-1° | 25 Mist 7° /-2° | 26 Partly cloudy 7° /0° | 27 Heavy rain 6° /1° | 28 Partly cloudy 7° /0° | 29 Partly cloudy 6° /-2° |\\n| 30 Sunny 5° /-2° |  |  |  |  |  |  | [...] You can expect about 3 to 8 days of rain in Trento during the month of November. It’s a good idea to bring along your umbrella so that you don’t get caught in poor weather.\\n\\nPlease note that Trento can expect a few days of snow in November.\\n\\nOur weather forecast can give you a great sense of what weather to expect in Trento in November 2025.\\n\\nIf you’re planning to visit Trento in the near future, we highly recommend that you review the 14 day weather forecast for Trento before you arrive.\", \"score\": 0.8593928, \"raw_content\": null}, {\"url\": \"https://www.accuweather.com/en/it/trento/216357/weather-forecast/216357\", \"title\": \"Trento, Trentino-Alto Adige, Italy Weather Forecast | AccuWeather\", \"content\": \"# Trento, Trentino-Alto Adige\\n\\nTrento\\n\\nTrentino-Alto Adige\\n\\n## Around the Globe\\n\\nAround the Globe\\n\\n### Hurricane Tracker\\n\\n### Severe Weather\\n\\n### Radar & Maps\\n\\n### News & Features\\n\\n### Astronomy\\n\\n### Business\\n\\n### Climate\\n\\n### Health\\n\\n### Recreation\\n\\n### Sports\\n\\n### Travel\\n\\n### Warnings\\n\\n### Data Suite\\n\\n### Forensics\\n\\n### Advertising\\n\\n### Superior Accuracy™\\n\\n### Video\\n\\n## Today\\n\\n## Today's Weather\\n\\nThu, Nov 6\\n\\nPlenty of sunshine\\nHi: 59° [...] Tonight: Partly cloudy; freezing temperatures in the normally colder spots\\nLo: 39°\\n\\n## Current Weather\\n\\n2:10 PM\\n\\n## Looking Ahead\\n\\nMostly sunny this weekend\\n\\n## Trento Weather Radar\\n\\nTrento Weather Radar\\n\\n## Hourly Weather\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\nrain drop\\n\\n## 10-Day Weather Forecast\\n\\nToday\\n\\n11/6\\n\\nPlenty of sunshine\\n\\nNight: Partly cloudy\\n\\nFri\\n\\n11/7\\n\\nSunny to partly cloudy\\n\\nClear\\n\\nSat\\n\\n11/8 [...] The air has reached a high level of pollution and is unhealthy for sensitive groups. Reduce time spent outside if you are feeling symptoms such as difficulty breathing or throat irritation.\\n\\n## Allergy Outlook\\n\\nTop Stories\\n\\nWinter Weather\\n\\nUpcoming cold wave to be accompanied by snow in Midwest, Appalachians\\n\\n2 hours ago\\n\\nRecreation\\n\\nHikers rescued from snowy trail on Vermont’s tallest mountain\\n\\n19 hours ago\\n\\nSevere Weather\\n\\nA 'gustnado' hit Massachusetts Monday night\\n\\n19 hours ago\", \"score\": 0.5968332, \"raw_content\": null}], \"response_time\": 4.53, \"request_id\": \"835e539f-af1e-44d0-98de-f3fd872c383b\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Today in Trento, Italy:\n",
      "- Conditions: Sunny with plenty of sunshine.\n",
      "- High/Low: About 15°C (59°F) / 4°C (39°F).\n",
      "- Tonight: Partly cloudy and chilly, with freezing temps in the colder spots.\n",
      "\n",
      "No rain is expected today. Would you like an hourly forecast or details in Celsius/Fahrenheit?\n"
     ]
    }
   ],
   "source": [
    "# Define the input message\n",
    "input_message = {\"messages\": {\"role\": \"user\", \"content\": query}}\n",
    "\n",
    "# Invoke the agent\n",
    "response = agent_executor.invoke(input_message)\n",
    "\n",
    "# Print the response\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fc51a",
   "metadata": {},
   "source": [
    "# Create our custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb5f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exam_score(exam_name: str) -> dict:\n",
    "    \"\"\"Get the expected score for a given exam.\"\"\"\n",
    "    \n",
    "    # For demonstration purposes, we assume a perfect score (we have high expectations!)\n",
    "    student_score = 30\n",
    "    \n",
    "    return {\n",
    "        'exam_name': exam_name, \n",
    "        'range': (0, 30), \n",
    "        'score': student_score}\n",
    "\n",
    "def parse_result(score: int) -> dict:\n",
    "    \"\"\"Get the expected result (pass or fail) for a given score.\"\"\"\n",
    "    \n",
    "    # For demonstration purposes, we assume a traditional passing threshold\n",
    "    pass_threshold = 18\n",
    "    \n",
    "    # Context: exam is graded out of 30, with 18 as the passing threshold\n",
    "    results = {\n",
    "        'score': score, \n",
    "        'pass_threshold': pass_threshold,\n",
    "        'passed': score >= pass_threshold,\n",
    "        'cum_laude': False # sorry :/\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29b01cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_agent(\n",
    "    model = llm_model, \n",
    "    tools = [get_exam_score, parse_result],\n",
    "    system_prompt = \"You are a helpful assistant that exploits all available tools to find up-to-date information and summarize it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d88a89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Will I ever pass the FM 2025 exam?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b030c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Will I ever pass the FM 2025 exam?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_exam_score (call_66PdA7LEjnlNscTNKtFquDX5)\n",
      " Call ID: call_66PdA7LEjnlNscTNKtFquDX5\n",
      "  Args:\n",
      "    exam_name: FM 2025\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_exam_score\n",
      "\n",
      "{\"exam_name\": \"FM 2025\", \"range\": [0, 30], \"score\": 30}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  parse_result (call_O0bvBt6sRT4RVQZAVFKLPr4T)\n",
      " Call ID: call_O0bvBt6sRT4RVQZAVFKLPr4T\n",
      "  Args:\n",
      "    score: 30\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: parse_result\n",
      "\n",
      "{\"score\": 30, \"pass_threshold\": 18, \"passed\": true, \"cum_laude\": false}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes. Based on the results, you’ve already passed FM 2025.\n",
      "\n",
      "- Score: 30/30\n",
      "- Pass threshold: 18\n",
      "- Passed: True\n",
      "- Cum laude: False\n",
      "\n",
      "If you want, I can help with a plan to maintain performance or aim for cum laude on future assessments.\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": {\"role\": \"user\", \"content\": query}})\n",
    "\n",
    "# Print the response\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92ddea",
   "metadata": {},
   "source": [
    "# Human in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f4413e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e662af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_agent(\n",
    "    model = llm_model, \n",
    "    tools = [get_exam_score, parse_result],\n",
    "    system_prompt = \"You are a helpful assistant that exploits all available tools to find up-to-date information.\",\n",
    "    #checkpointer=InMemorySaver(thread_id=\"main_conversation\", checkpoint_ns=\"exam_agent\"),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"parse_result\": {\n",
    "                    \"accepted\": [\"yes\", \"no\", \"reject\"],\n",
    "                }\n",
    "            }\n",
    "        ),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48fb5c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 476, 'prompt_tokens': 188, 'total_tokens': 664, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYu4xYKgQG3tmVFGibJm9UJs42Ixb', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--86259c8a-6761-470c-b62a-6705f86769b2-0', tool_calls=[{'name': 'get_exam_score', 'args': {'exam_name': 'FM 2025'}, 'id': 'call_qJtYW6c0tU5f6JrQ8fRPZnpG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 188, 'output_tokens': 476, 'total_tokens': 664, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}})]}}\n",
      "{'HumanInTheLoopMiddleware.after_model': None}\n",
      "{'tools': {'messages': [ToolMessage(content='{\"exam_name\": \"FM 2025\", \"range\": [0, 30], \"score\": 30}', name='get_exam_score', id='6000d535-45c0-4901-b896-68712cebb7a9', tool_call_id='call_qJtYW6c0tU5f6JrQ8fRPZnpG')]}}\n",
      "{'model': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 343, 'prompt_tokens': 247, 'total_tokens': 590, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYu5PsXO7PyxKjAnvuFIiHgHBOjir', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--920df8d3-838d-43ad-9764-6aa4f96cbf2a-0', tool_calls=[{'name': 'parse_result', 'args': {'score': 30}, 'id': 'call_GsMXUH6DIwnSjs5s49xgxzAn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 247, 'output_tokens': 343, 'total_tokens': 590, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}})]}}\n",
      "{'HumanInTheLoopMiddleware.after_model': None}\n",
      "{'tools': {'messages': [ToolMessage(content='{\"score\": 30, \"pass_threshold\": 18, \"passed\": true, \"cum_laude\": false}', name='parse_result', id='1dbfd928-fe7c-4f41-9065-813c07b7c9c2', tool_call_id='call_GsMXUH6DIwnSjs5s49xgxzAn')]}}\n",
      "{'model': {'messages': [AIMessage(content='Yes. You’ve already passed FM 2025.\\n\\n- Score: 30/30 (perfect)\\n- Pass threshold: 18\\n- Cum laude: not awarded this time\\n\\nWould you like tips to aim for cum laude next time or a study plan for future exams?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 707, 'prompt_tokens': 300, 'total_tokens': 1007, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CYu5VznE67B0vHa3UTxtjr29WLE6o', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e72eacce-e44d-446c-866a-1d594ed551f1-0', usage_metadata={'input_tokens': 300, 'output_tokens': 707, 'total_tokens': 1007, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}})]}}\n",
      "{'HumanInTheLoopMiddleware.after_model': None}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"messages\": {\"role\": \"user\", \"content\": query}})\n",
    "\n",
    "# Print the response\n",
    "for state in agent_executor.stream({\"messages\": {\"role\": \"user\", \"content\": query}}):\n",
    "    print(state)\n",
    "#for message in response[\"messages\"]:\n",
    "#    message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
