{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpjpb1HqQ9TbqT4LanIKwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saturnMars/FM_2025/blob/main/Lab1_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "2fuw4oEfeNr1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the labelled datasets for classification\n",
        "1. **Language**\n",
        "2. **Truthfulness** (*[The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets](https://github.com/saprmarks/geometry-of-truth/tree/main)*)"
      ],
      "metadata": {
        "id": "vxIC-kNdef2m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "eNlcyFegdk4j",
        "outputId": "70eb5908-fa81-4590-8aa2-7d2198900197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-16 12:55:25--  https://amazon-massive-nlu-dataset.s3.amazonaws.com/amazon-massive-dataset-1.1.tar.gz\n",
            "Resolving amazon-massive-nlu-dataset.s3.amazonaws.com (amazon-massive-nlu-dataset.s3.amazonaws.com)... 52.216.240.236, 16.15.208.142, 52.216.106.188, ...\n",
            "Connecting to amazon-massive-nlu-dataset.s3.amazonaws.com (amazon-massive-nlu-dataset.s3.amazonaws.com)|52.216.240.236|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40251390 (38M) [application/x-gzip]\n",
            "Saving to: ‘amazon-massive-dataset-1.1.tar.gz.2’\n",
            "\n",
            "amazon-massive-data 100%[===================>]  38.39M  72.8MB/s    in 0.5s    \n",
            "\n",
            "2025-09-16 12:55:26 (72.8 MB/s) - ‘amazon-massive-dataset-1.1.tar.gz.2’ saved [40251390/40251390]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-156778073.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"amazon-massive-dataset-1.1.tar.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r:gz\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m      \u001b[0mlanguages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en-US.jsonl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m      \u001b[0mlanguages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'it'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'it-IT.jsonl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "# LANGUAGE ()\n",
        "!wget https://amazon-massive-nlu-dataset.s3.amazonaws.com/amazon-massive-dataset-1.1.tar.gz\n",
        "dfs = []\n",
        "with tarfile.open(\"amazon-massive-dataset-1.1.tar.gz\", \"r:gz\") as tar:\n",
        "     dfs['en'] = pd.read_json(path.join('data', 'en-US.jsonl'),lines = True)\n",
        "     dfs['it'] = pd.read_json(path.join('data', 'it-IT.jsonl'),lines = True)\n",
        "df = pd.concat(dfs)\n",
        "print(df.iloc[-1])\n",
        "print(df)\n",
        "exit()\n",
        "\n",
        "# and member.name.contains\n",
        "\n",
        "\n",
        "# TRUTHFULNESS (true/false claims, binary classification)\n",
        "truthfulness_df = pd.read_csv(\"https://raw.githubusercontent.com/saprmarks/geometry-of-truth/refs/heads/main/datasets/counterfact_true_false.csv\")[['statement', 'label']]\n",
        "print('-' * 25, 'TRUTHFULNESS', '-' * 25, '\\n', truthfulness_df)"
      ]
    }
  ]
}