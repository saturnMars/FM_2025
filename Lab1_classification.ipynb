{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOO/DyqpXlaMmyC6t3tuvG3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd43017882db4f3ba67bb8f15118402d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d044d37b3b7f4de985db1cbf07dfe406",
              "IPY_MODEL_9ba26ed6fef74a95b035e54847f30efc",
              "IPY_MODEL_baeb33ad6eef4c30b039b408b7daf20a"
            ],
            "layout": "IPY_MODEL_ce84fc8df44a412bb7e929a6860f0b7f"
          }
        },
        "d044d37b3b7f4de985db1cbf07dfe406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e074e7cb5d4c55a0850d8303b66557",
            "placeholder": "​",
            "style": "IPY_MODEL_d60dabdb3fcd462cb9bc0ae6af28ccd3",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "9ba26ed6fef74a95b035e54847f30efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5082d6f16af94390b5f430b990e48706",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_527e9bb2bbf04ff599f217bbc5b6b0bd",
            "value": 0
          }
        },
        "baeb33ad6eef4c30b039b408b7daf20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c1f4c23e8564d33a7434c740680b001",
            "placeholder": "​",
            "style": "IPY_MODEL_fb5465b71641452fa948d3a333b437b2",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "ce84fc8df44a412bb7e929a6860f0b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e074e7cb5d4c55a0850d8303b66557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60dabdb3fcd462cb9bc0ae6af28ccd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5082d6f16af94390b5f430b990e48706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527e9bb2bbf04ff599f217bbc5b6b0bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c1f4c23e8564d33a7434c740680b001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5465b71641452fa948d3a333b437b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saturnMars/FM_2025/blob/main/Lab1_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "import pandas as pd\n",
        "import tarfile"
      ],
      "metadata": {
        "id": "2fuw4oEfeNr1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the labelled datasets for:\n",
        "- ***binary* classification**:\n",
        "    1. **Truthfulness** (True/false claims)\n",
        "        - *[The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets](https://github.com/saprmarks/geometry-of-truth/tree/main)*\n",
        "    2. **Subjectivity** (subjective/objetive sentences)\n",
        "        - [CLEF 2025, Task 1 - Subjectivity](https://checkthat.gitlab.io/clef2025/task1/)\n",
        "- ***multiclass* classification**:\n",
        "    3. **Tense** (past/present/future)\n",
        "        - [EnglishTense: A large scale English texts dataset categorized into three categories: Past, Present, Future tenses.](https://data.mendeley.com/datasets/jnb2xp9m4r/2)\n",
        "    4. **Language** (utterances from multiple languages)\n",
        "        - [MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages](https://github.com/alexa/massive)\n",
        "\n"
      ],
      "metadata": {
        "id": "vxIC-kNdef2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.mendeley.com/public-files/datasets/jnb2xp9m4r/files/8148432a-a69a-473f-beb6-835d2a176f30/file_downloaded"
      ],
      "metadata": {
        "id": "3ZYS80qW5T_n",
        "outputId": "80190c57-3862-4d80-8e0a-d6d175825dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-26 10:21:39--  https://data.mendeley.com/public-files/datasets/jnb2xp9m4r/files/8148432a-a69a-473f-beb6-835d2a176f30/file_downloaded\n",
            "Resolving data.mendeley.com (data.mendeley.com)... 162.159.130.86, 162.159.133.86\n",
            "Connecting to data.mendeley.com (data.mendeley.com)|162.159.130.86|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/28304dc7-a47c-4d83-bdcc-2edc535236d8 [following]\n",
            "--2025-09-26 10:21:40--  https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/28304dc7-a47c-4d83-bdcc-2edc535236d8\n",
            "Resolving prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com)... 52.92.17.50, 3.5.64.49, 3.5.65.18, ...\n",
            "Connecting to prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com)|52.92.17.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 458307 (448K) [application/vnd.openxmlformats-officedocument.spreadsheetml.sheet]\n",
            "Saving to: ‘file_downloaded.28’\n",
            "\n",
            "file_downloaded.28  100%[===================>] 447.57K   764KB/s    in 0.6s    \n",
            "\n",
            "2025-09-26 10:21:42 (764 KB/s) - ‘file_downloaded.28’ saved [458307/458307]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNlcyFegdk4j",
        "outputId": "b6753cba-99c1-4674-d927-228c04539baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-26 10:21:49--  https://amazon-massive-nlu-dataset.s3.amazonaws.com/amazon-massive-dataset-1.1.tar.gz\n",
            "Resolving amazon-massive-nlu-dataset.s3.amazonaws.com (amazon-massive-nlu-dataset.s3.amazonaws.com)... 3.5.9.165, 16.15.217.213, 3.5.29.26, ...\n",
            "Connecting to amazon-massive-nlu-dataset.s3.amazonaws.com (amazon-massive-nlu-dataset.s3.amazonaws.com)|3.5.9.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40251390 (38M) [application/x-gzip]\n",
            "Saving to: ‘amazon-massive-dataset-1.1.tar.gz.28’\n",
            "\n",
            "amazon-massive-data 100%[===================>]  38.39M  31.9MB/s    in 1.2s    \n",
            "\n",
            "2025-09-26 10:21:50 (31.9 MB/s) - ‘amazon-massive-dataset-1.1.tar.gz.28’ saved [40251390/40251390]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# (1) TRUTHFULNESS (The Geometry of Truth; TRUE|FALSE)\n",
        "truthfulness_df = pd.read_csv(\"https://raw.githubusercontent.com/saprmarks/geometry-of-truth/refs/heads/main/datasets/counterfact_true_false.csv\")\n",
        "truthfulness_df = truthfulness_df[['statement', 'label']].rename(columns = {'statement':'doc'})\n",
        "\n",
        "# (2) SUBJECTIVITY (CLEF2025; SUB|OBJ)\n",
        "subjectivity_df = pd.concat([\n",
        "    pd.read_csv(\"https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task1/data/english/train_en.tsv\", sep= '\\t'),\n",
        "    pd.read_csv(\"https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task1/data/english/dev_en.tsv\", sep= '\\t'),\n",
        "    pd.read_csv(\"https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task1/data/english/dev_test_en.tsv\", sep= '\\t'),\n",
        "    pd.read_csv(\"https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/raw/main/task1/data/english/test_en_labeled.tsv\", sep= '\\t'),\n",
        "])\n",
        "subjectivity_df = subjectivity_df[['sentence', 'label']].rename(columns = {'sentence':'doc'})\n",
        "\n",
        "# (3) TENSE (EnglishTense; past|present|future)\n",
        "tense_df = pd.read_excel(\"https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/28304dc7-a47c-4d83-bdcc-2edc535236d8\").rename(columns = {'Sentence':'doc', 'Labels':'label'})\n",
        "tense_df['label'] = tense_df['label'].str.upper() # Turnaround to fix a bug in the dataset labels\n",
        "\n",
        "# (4) LANGUAGE (MASSIVE; EN/IT/DE/ES)\n",
        "!wget https://amazon-massive-nlu-dataset.s3.amazonaws.com/amazon-massive-dataset-1.1.tar.gz\n",
        "dfs = []\n",
        "with tarfile.open(\"amazon-massive-dataset-1.1.tar.gz\", \"r:gz\") as tar:\n",
        "    for lang in ['en-US', 'it-IT', 'de-DE', 'es-ES']:\n",
        "      dfs.append(pd.read_json(tar.extractfile(path.join('1.1','data', f'{lang}.jsonl')), lines = True))\n",
        "language_df = pd.concat(dfs)[['utt', 'locale']].rename(columns = {'utt':'doc', 'locale': 'label'})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration"
      ],
      "metadata": {
        "id": "6e2X9PM43AQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRUTHFULNESS dataset\n",
        "print('-' * 30, 'TRUTHFULNESS', '-' * 30)\n",
        "print(f\"CLASSES ({truthfulness_df['label'].nunique()}):\", '|'.join(truthfulness_df['label'].map(str).unique()), '\\n')\n",
        "print(truthfulness_df)\n",
        "\n",
        "# SUBJECTIVITY dataset\n",
        "print('-' * 30, 'SUBJECTIVITY', '-' * 30)\n",
        "print(f\"CLASSES ({subjectivity_df['label'].nunique()}):\", '|'.join(subjectivity_df['label'].unique()), '\\n')\n",
        "print(subjectivity_df)\n",
        "\n",
        "# TENSE dataset\n",
        "print('-' * 30, 'TENSE', '-' * 30)\n",
        "print(f\"CLASSES ({tense_df['label'].nunique()}):\", '|'.join(tense_df['label'].unique()), '\\n')\n",
        "print(tense_df)\n",
        "\n",
        "# LANGUAGE dataset\n",
        "print('-' * 30, 'LANGUAGE', '-' * 30)\n",
        "print(f\"CLASSES ({language_df['label'].nunique()}):\", '|'.join(language_df['label'].unique()), '\\n')\n",
        "print(language_df)"
      ],
      "metadata": {
        "id": "aJLer5yI2gI8",
        "outputId": "37a9a335-28c4-4924-c1bc-91fe58e866a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------ TRUTHFULNESS ------------------------------\n",
            "CLASSES (2): 1|0 \n",
            "\n",
            "                                                     doc  label\n",
            "0      The mother tongue of Danielle Darrieux is French.      1\n",
            "1      The mother tongue of Danielle Darrieux is Engl...      0\n",
            "2      The official religion of Edwin of Northumbria ...      1\n",
            "3      The official religion of Edwin of Northumbria ...      0\n",
            "4      The mother tongue of Thomas Joannes Stieltjes ...      1\n",
            "...                                                  ...    ...\n",
            "31959          Jerusalem of Gold was written in Finnish.      0\n",
            "31960  The language used by Jean-Pierre Dionnet is Fr...      1\n",
            "31961  The language used by Jean-Pierre Dionnet is Sp...      0\n",
            "31962                             Subair works as actor.      1\n",
            "31963                          Subair works as composer.      0\n",
            "\n",
            "[31964 rows x 2 columns]\n",
            "------------------------------ SUBJECTIVITY ------------------------------\n",
            "CLASSES (2): SUBJ|OBJ \n",
            "\n",
            "                                                   doc label\n",
            "0    Gone are the days when they led the world in r...  SUBJ\n",
            "1    The trend is expected to reverse as soon as ne...   OBJ\n",
            "2               But there is the specious point again.   OBJ\n",
            "3    He added he wouldn’t be surprised to see a new...   OBJ\n",
            "4    Not less government, you see; the same amount ...  SUBJ\n",
            "..                                                 ...   ...\n",
            "295       She’s also pretty good at winning elections.  SUBJ\n",
            "296  Is the chancellor discombobulated by the anger...  SUBJ\n",
            "297  Realising what my noise habit was doing to me ...  SUBJ\n",
            "298  There are fierce arguments about whether Heath...   OBJ\n",
            "299  None of us are strangers to the negative effec...  SUBJ\n",
            "\n",
            "[2076 rows x 2 columns]\n",
            "------------------------------ TENSE ------------------------------\n",
            "CLASSES (3): FUTURE|PRESENT|PAST \n",
            "\n",
            "                                                     doc    label\n",
            "0      by 2050 ai architects will have designed selfc...   FUTURE\n",
            "1      in the future sustainable transportation optio...   FUTURE\n",
            "2      china has been actively involved in peacekeepi...  PRESENT\n",
            "3      educational diversity is a hallmark of foreign...  PRESENT\n",
            "4        the coach substituted an underperforming player     PAST\n",
            "...                                                  ...      ...\n",
            "13311                       he will become a good person   FUTURE\n",
            "13312                      their door opens after eleven  PRESENT\n",
            "13313                 my mother will cook delicious food   FUTURE\n",
            "13314                        i am going to win this race   FUTURE\n",
            "13315              dona will buy a new mobile next month   FUTURE\n",
            "\n",
            "[13316 rows x 2 columns]\n",
            "------------------------------ LANGUAGE ------------------------------\n",
            "CLASSES (4): en-US|it-IT|de-DE|es-ES \n",
            "\n",
            "                                            doc  label\n",
            "0               wake me up at five am this week  en-US\n",
            "1               wake me up at nine am on friday  en-US\n",
            "2           set an alarm for two hours from now  en-US\n",
            "3                                         quiet  en-US\n",
            "4                                    olly quiet  en-US\n",
            "...                                         ...    ...\n",
            "16516                tengo correos electrónicos  es-ES\n",
            "16517           hay correos electrónicos nuevos  es-ES\n",
            "16518             tengo un nuevo correo de juan  es-ES\n",
            "16519  me ha enviado juan un correo electrónico  es-ES\n",
            "16520         revisa correo electrónico de juan  es-ES\n",
            "\n",
            "[66084 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create *Dataset*, *DataLoader* (PyTorch), and *DataModule* (PyTorch Lightining) for training\n",
        "1. PyTorch: [Dataset/DataLoader](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
        "2. PyTorch Lightining [DataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html)\n"
      ],
      "metadata": {
        "id": "BcVEVSY3II1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch"
      ],
      "metadata": {
        "id": "WeNuoMpzIQR3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df:pd.DataFrame):\n",
        "\n",
        "        # Create our inputs (X)\n",
        "        self.inputs = df['doc'].values\n",
        "\n",
        "        # Convert the textual labels into numbers (CLASS A --> 0, CLASS B --> 1, ...)\n",
        "        self.class_mapping = {label: i for i, label in enumerate(df['label'].unique())}\n",
        "\n",
        "        # Create our outputs (y)\n",
        "        self.targets = df['label'].map(self.class_mapping).values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.targets[idx]\n"
      ],
      "metadata": {
        "id": "YckxFu1TJT9C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niqD_TwlOr8k",
        "outputId": "7534f6e9-744b-4440-dd97-762d18faa921"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightning in /usr/local/lib/python3.12/dist-packages (2.5.5)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (0.15.2)\n",
            "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (1.8.2)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.15.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning) (2.5.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.12.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics<3.0,>0.7.0->lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.20.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning import LightningDataModule"
      ],
      "metadata": {
        "id": "yqRBoxA4L5Ko"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataModule(LightningDataModule):\n",
        "    def __init__(self, data: Dataset, batch_size: int = 32, val_size:float = 0.1, test_size:float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize the variables\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.train_size = 1 - val_size - test_size\n",
        "        self.val_size = val_size\n",
        "        self.test_size = test_size\n",
        "\n",
        "        # Set the seed for reproducibility\n",
        "        self.random_seed = 101\n",
        "\n",
        "    def setup(self, stage:str):\n",
        "\n",
        "        # Create the splits\n",
        "        train_set, val_set, test_set = random_split(\n",
        "            dataset = self.data,\n",
        "            generator = torch.Generator().manual_seed(self.random_seed),\n",
        "            lengths = [self.train_size, self.val_size, self.test_size])\n",
        "\n",
        "        self.train_set = train_set\n",
        "        self.val_set = val_set\n",
        "        self.test_set = test_set\n",
        "\n",
        "        print('\\nINPUTS:', len(self.data), '--> TRAIN:', round(((len(self.train_set) / len(self.data)) * 100), 1), '%',\n",
        "              '|| VALIDATION:', round(((len(self.val_set) / len(self.data)) * 100), 1), '%',\n",
        "              '|| TEST:', round(((len(self.test_set) / len(self.data)) * 100), 1), '%', '\\n')\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set, batch_size = self.batch_size, shuffle = True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_set, batch_size = self.batch_size, shuffle = False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set, batch_size = self.batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "ilFDZG5VLqFN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore the dataloader"
      ],
      "metadata": {
        "id": "FWg138kwP9M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the dataset and the dataloders\n",
        "dataset = MyDataset(tense_df)\n",
        "dataloaders = MyDataModule(dataset, batch_size = 32, val_size = 0.1, test_size = 0.1)\n",
        "\n",
        "# Create the splits and explore the train loader\n",
        "dataloaders.setup('')\n",
        "train_set = dataloaders.train_dataloader()\n",
        "\n",
        "# Get the first batch\n",
        "x, y = list(train_set)[0]\n",
        "label_mapping = {v: k for k, v in dataset.class_mapping.items()}\n",
        "for x_item, y_item in zip(x, y):\n",
        "    print(\"DOC:\", x_item, \"--> CLASS:\", y_item.item(), f'({label_mapping[y_item.item()]})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDe9et3IP79G",
        "outputId": "f9e7c5c8-ffe7-44b3-e062-3db79c58c6ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INPUTS: 13316 --> TRAIN: 80.0 % || VALIDATION: 10.0 % || TEST: 10.0 % \n",
            "\n",
            "DOC: in the future chatbots will assist with medical teleconsultations and remote patient monitoring --> CLASS: 0 (FUTURE)\n",
            "DOC: researchers investigate microbial genetics and molecular biology --> CLASS: 1 (PRESENT)\n",
            "DOC: by next semester they will have been integrating artificial intelligence for personalized learning --> CLASS: 0 (FUTURE)\n",
            "DOC: transfer learning in computer vision often involves using pretrained models like efficientnet and mobilenet for feature extraction and classification --> CLASS: 1 (PRESENT)\n",
            "DOC: online support resources will offer guidance on making digital content accessible --> CLASS: 0 (FUTURE)\n",
            "DOC: with a loud purr the contented cat rubs its head against my leg --> CLASS: 1 (PRESENT)\n",
            "DOC: by next summer they will have been tending to their bonsai trees for a decade --> CLASS: 0 (FUTURE)\n",
            "DOC: in the future chatbots will assist with legal paperwork and documentation --> CLASS: 0 (FUTURE)\n",
            "DOC: in a years time they will have been building robots for six years --> CLASS: 0 (FUTURE)\n",
            "DOC: the school implemented a peer mentoring program --> CLASS: 2 (PAST)\n",
            "DOC: they experimented with a keto diet to lose weight --> CLASS: 2 (PAST)\n",
            "DOC: women in stem have actively participated in initiatives promoting diversity in stem funding allocation --> CLASS: 1 (PRESENT)\n",
            "DOC: they will overcome obstacles with resilience --> CLASS: 0 (FUTURE)\n",
            "DOC: women in stem have actively participated in initiatives promoting stem education for girls --> CLASS: 1 (PRESENT)\n",
            "DOC: by 2120 nanotechnologists will have constructed molecularscale machines --> CLASS: 0 (FUTURE)\n",
            "DOC: before the storm arrived the moon had shone brightly --> CLASS: 2 (PAST)\n",
            "DOC: experimentalists are conducting precision measurements to test the laws of thermodynamics --> CLASS: 1 (PRESENT)\n",
            "DOC: tomorrow morning well be pruning the roses for better shape --> CLASS: 0 (FUTURE)\n",
            "DOC: teachers will have been using ai assistants to grade assignments and provide feedback --> CLASS: 0 (FUTURE)\n",
            "DOC: she was sleeping with her face buried in the pillow --> CLASS: 2 (PAST)\n",
            "DOC: gamers have celebrated the impact of video games on technological innovation --> CLASS: 1 (PRESENT)\n",
            "DOC: the audiobook plays in the background as i complete chores around the house --> CLASS: 1 (PRESENT)\n",
            "DOC: it will be assisting in sports analytics --> CLASS: 0 (FUTURE)\n",
            "DOC: the vibrant colors of the northern lights dance across the night sky creating a mesmerizing spectacle --> CLASS: 1 (PRESENT)\n",
            "DOC: he will become a doctor --> CLASS: 0 (FUTURE)\n",
            "DOC: we had celebrated our victory in the badminton league with a team dinner --> CLASS: 2 (PAST)\n",
            "DOC: physicists will be experimenting with novel materials for quantum computing --> CLASS: 0 (FUTURE)\n",
            "DOC: users have been sharing their travel experiences on facebook --> CLASS: 1 (PRESENT)\n",
            "DOC: developers will have been refactoring code regularly --> CLASS: 0 (FUTURE)\n",
            "DOC: my father will go to brazil --> CLASS: 0 (FUTURE)\n",
            "DOC: designers have embraced the use of sustainable alternatives to traditional down such as recycled polyester --> CLASS: 1 (PRESENT)\n",
            "DOC: by 2050 amorphous computing will have become the cornerstone of artificial intelligence systems --> CLASS: 0 (FUTURE)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create our custom model for classification: a frozen LLM with a Multi Layer Perceptron (MLP)"
      ],
      "metadata": {
        "id": "sGIkgriGR6Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "metadata": {
        "id": "kU2rFz5kSUzq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, llm_name:str, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Set the latent dimension\n",
        "        self.latent_dim = 512\n",
        "\n",
        "        # Set the probability for the dropout layer\n",
        "        self.drop_p = 0.3\n",
        "\n",
        "        # Load the foundation language model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(llm_name)\n",
        "        self.llm = AutoModel.from_pretrained(llm_name)\n",
        "\n",
        "        # Define the token for padding and its direction\n",
        "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "        self.tokenizer.padding_side = 'left'\n",
        "\n",
        "        # Create our custom layers\n",
        "        self.decoder_layer = nn.Sequential(\n",
        "\n",
        "            # Layer 0\n",
        "            nn.Linear(self.llm.config.hidden_size, self.latent_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(self.latent_dim),\n",
        "            nn.Dropout(self.drop_p),\n",
        "\n",
        "            # Layer 1\n",
        "            nn.Linear(self.latent_dim, self.latent_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(self.latent_dim)\n",
        "        )\n",
        "\n",
        "        # Create our output layer\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.LayerNorm(self.latent_dim),\n",
        "            nn.Linear(self.latent_dim, self.num_classes),\n",
        "            nn.Softmax(dim = 1) # Get probability distribution over the classes [batch_size, num_classes]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Tokenize the textual document (x)\n",
        "        input_ids = self.tokenizer(x, padding = True, return_tensors = 'pt').to(self.llm.device)\n",
        "\n",
        "        # Process the tokenized document using the frozen LLM\n",
        "        llm_output = self.llm(**input_ids)\n",
        "\n",
        "        # Get the embeddings from the median hidden layer [batch_size, num_layers, hidden_dim]\n",
        "        median_layer = self.llm.config.num_hidden_layers // 2\n",
        "        embeddings = llm_output['last_hidden_state'][:, median_layer, :]\n",
        "\n",
        "        # Learn the latent fetures from the LLM embeddings\n",
        "        out = self.decoder_layer(embeddings)\n",
        "\n",
        "        # Output layer with the SoftMax\n",
        "        out = self.output_layer(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "Sb9kJVzDSOgm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why do we consider the median hidden layer?"
      ],
      "metadata": {
        "id": "sZ4Y8xvQf00N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the loss function and the training process"
      ],
      "metadata": {
        "id": "woHOnid7XlfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning import LightningModule\n",
        "from torchmetrics.classification import F1Score, Precision, Recall"
      ],
      "metadata": {
        "id": "c7w3dQrKXEqu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(LightningModule):\n",
        "    def __init__(self, llm_name:str, num_classes: int, lr:float):\n",
        "        super().__init__()\n",
        "\n",
        "        # Unpacked the configs\n",
        "        self.lr = lr\n",
        "\n",
        "        # Load our custom model\n",
        "        self.model = Network(llm_name, num_classes)\n",
        "\n",
        "        # Define the loss function\n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Define the classification metrics for the train, validation and test sets\n",
        "        self.train_f1 = F1Score(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "        self.train_precision = Precision(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "        self.train_recall = Recall(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "\n",
        "        self.val_f1 = F1Score(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "        self.val_precision = Precision(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "        self.val_recall = Recall(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "\n",
        "        self.test_f1 = F1Score(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "        self.test_precision = Precision(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "        self.test_recall = Recall(task=\"multiclass\", num_classes = num_classes, average=\"macro\")\n",
        "\n",
        "        self.val_history = {'F1': [], 'precision': [], 'recall': []}\n",
        "\n",
        "    # Define the optimizer\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr = self.lr)\n",
        "        return optimizer\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def _step(self, batch, batch_idx):\n",
        "\n",
        "        # Unpack the batch\n",
        "        docs, labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = self(docs)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = self.loss_function(outputs, labels.flatten())\n",
        "\n",
        "        # Get the most likely class\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        return loss, preds, labels\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, preds, labels  = self._step(batch, batch_idx)\n",
        "\n",
        "        # Compute the classification metrics\n",
        "        self.train_precision.update(preds, labels)\n",
        "        self.train_recall.update(preds, labels)\n",
        "        self.train_f1.update(preds, labels)\n",
        "\n",
        "        # Log metrics\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_precision', self.train_precision, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_recall', self.train_recall, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_f1', self.train_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        with torch.inference_mode():\n",
        "            loss, preds, labels  = self._step(batch, batch_idx)\n",
        "\n",
        "        # Compute the classification metrics\n",
        "        self.val_precision.update(preds, labels)\n",
        "        self.val_recall.update(preds, labels)\n",
        "        self.val_f1.update(preds, labels)\n",
        "\n",
        "        # Log metrics\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_precision', self.val_precision, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_recall', self.val_recall, on_step=False, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.val_history['precision'].append(self.trainer.callback_metrics[\"val_precision\"].item())\n",
        "        self.val_history['recall'].append(self.trainer.callback_metrics[\"val_recall\"].item())\n",
        "        self.val_history['F1'].append(self.trainer.callback_metrics[\"val_f1\"].item())\n",
        "\n",
        "        # Visualize the values\n",
        "        df = pd.DataFrame(self.val_history)\n",
        "        if len(df) > 1:\n",
        "            plot_values(df, epoch_number = self.current_epoch + 1)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        with torch.inference_mode():\n",
        "            _, preds, labels  = self._step(batch, batch_idx)\n",
        "\n",
        "        # Compute the classification metrics\n",
        "        self.test_precision.update(preds, labels)\n",
        "        self.test_recall.update(preds, labels)\n",
        "        self.test_f1.update(preds, labels)\n",
        "\n",
        "        # Log metrics\n",
        "        self.log('test_precision', self.test_precision, on_epoch=True, prog_bar=True)\n",
        "        self.log('test_recall', self.test_recall, on_epoch=True, prog_bar=True)\n",
        "        self.log('test_f1', self.test_f1, on_epoch=True, prog_bar=True)\n"
      ],
      "metadata": {
        "id": "BaxP8SacW_mn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.ticker import MaxNLocator\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "X23txBAzZP6T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_values(df, epoch_number):\n",
        "    colors = {'f1': 'tab:blue', 'precision': 'tab:green', 'recall': 'tab:orange'}\n",
        "\n",
        "    # Plot the metrics as lines\n",
        "    sns.lineplot(data = df, palette = colors, marker = 'o')\n",
        "\n",
        "    # Some graphical setting\n",
        "    ax = plt.gca()\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    ax.set_title(f'VALIDATION (epoch {epoch_number})')\n",
        "    ax.grid(True)\n",
        "    ax.ylim(0, 1)\n",
        "    ax.legend(title=\"Metric\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rnuohNOBVTBT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train our custom neural models with Pytorch Lighting\n",
        "truthfulness_df | subjectivity_df | tense_df | language_df"
      ],
      "metadata": {
        "id": "4C2y_zDzWlnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "data = tense_df"
      ],
      "metadata": {
        "id": "NndTpyOcaZSM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. EleutherAI's Pythia\n",
        "    - EleutherAI/pythia-160m\n",
        "    - EleutherAI/pythia-1.4b\n",
        "    - EleutherAI/pythia-6.9b\n",
        "2. MetaAI's Llama\n",
        "    - meta-llama/Llama-3.1-8B\n",
        "    - meta-llama/Llama-3.2-1B\n",
        "3. OpenAI's GPT-2\n",
        "    - openai-community/gpt2-medium\n",
        "    - openai-community/gpt2-xl\n",
        "3. Google's BERT\n",
        "    - google-bert/bert-base-uncased"
      ],
      "metadata": {
        "id": "2mBT84wAxKHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(\n",
        "    llm_name = 'EleutherAI/pythia-6.9b',\n",
        "    num_classes = data['label'].nunique(),\n",
        "    lr = 1e-3)\n",
        "dataloaders = MyDataModule(MyDataset(data), batch_size = 32, val_size = 0.1, test_size = 0.1)"
      ],
      "metadata": {
        "id": "MX5OzamuWw6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "cd43017882db4f3ba67bb8f15118402d",
            "d044d37b3b7f4de985db1cbf07dfe406",
            "9ba26ed6fef74a95b035e54847f30efc",
            "baeb33ad6eef4c30b039b408b7daf20a",
            "ce84fc8df44a412bb7e929a6860f0b7f",
            "91e074e7cb5d4c55a0850d8303b66557",
            "d60dabdb3fcd462cb9bc0ae6af28ccd3",
            "5082d6f16af94390b5f430b990e48706",
            "527e9bb2bbf04ff599f217bbc5b6b0bd",
            "8c1f4c23e8564d33a7434c740680b001",
            "fb5465b71641452fa948d3a333b437b2"
          ]
        },
        "outputId": "f67627f5-60eb-4a9c-f062-2d3443740882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd43017882db4f3ba67bb8f15118402d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning import Trainer"
      ],
      "metadata": {
        "id": "sDrRxDFzaVGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(max_epochs = num_epochs)\n",
        "trainer.fit(model, datamodule=dataloaders)"
      ],
      "metadata": {
        "id": "sf_F7E3QZ-BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute metrics on the test set"
      ],
      "metadata": {
        "id": "LtJWlc0NSvYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = trainer.test(model = model, datamodule=dataloaders)"
      ],
      "metadata": {
        "id": "q99JQI0eSvAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}